{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "<img src=\"../images/validation_comic.jpg\" width=\"550\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Optimize Model Parameters?\n",
    "Determining the optimal model parameters is a critical aspect of hyperparameter tuning. Most machine learning models possess a set of parameters that need to be defined before the training process commences. Take, for example, ElasticNet regression, which has both the $l1$ and $l2$ ($\\alpha$) norm penalties.\n",
    "\n",
    "One approach to parameter tuning involves haphazardly experimenting with different values, hoping to stumble upon settings that yield improved performance. However, a smarter and more systematic method is available, known as model validation.\n",
    "\n",
    "### The Significance of Model Validation\n",
    "In the realm of supervised learning, data is typically divided into two distinct subsets:\n",
    "- **Training:** This phase allows the model to comprehend the underlying data patterns.\n",
    "- **Testing:** This stage is designed to ensure that our model generalizes well on new, unseen data.\n",
    "\n",
    "In situations where the dataset's size permits, introducing a third set can be invaluable:\n",
    "\n",
    "- **Validation:** Here, the model can explore and determine the most suitable hyperparameters while also identifying signs of overfitting.\n",
    "\n",
    "The validation set is instrumental in evaluating the performance of our trained models under various hyperparameter configurations. Furthermore, it serves as a valuable tool for detecting and addressing overfitting, where the model excels in training data but fails to generalize to new data. By employing this approach, we ensure that our testing set remains entirely independent from any decisions regarding our model, thereby safeguarding against potential data snooping\n",
    "\n",
    "### Cross Validation\n",
    "<div style=\"display: flex; align-items: center;\">\n",
    "  <img src=\"../images/cross_validation_diagram_1.png\" height=\"150\"/>\n",
    "  <div style=\"width: 50px;\"></div>\n",
    "  <img src=\"../images/cross_validation_diagram_2.ppm\" height=\"150\"/>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Working with smaller datasets can be challenging. In such scenarios, we cannot afford to set aside a dedicated validation subset, as every bit of training data is precious.\n",
    "\n",
    "This is where cross-validation comes to the rescue. Cross-validation involves the following steps:\n",
    "\n",
    "1. Dividing the data into \"folds\", which are smaller, distinct subsets.\n",
    "2. Reserving one fold as the testing set while training the model on the remaining folds.\n",
    "3. Repeating this process, using each fold as a testing set once.\n",
    "4. Averaging the model's performance over all testing folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by fitting an ElasticNet regression model with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Deafault Model ------\n",
      "R^2: 0.41\n",
      "MSE: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Load housing data and split it into train/test\n",
    "np.random.seed(0)\n",
    "data = fetch_california_housing()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Fit the models on the training data\n",
    "ols = ElasticNet()\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "print(\"------ Deafault Model ------\")\n",
    "y_pred = ols.predict(X_test)\n",
    "print(\"R^2: %.2f\" % r2_score(y_test, y_pred))\n",
    "print(\"MSE: %.2f\" % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform cross validation in order to find the optimal ElasticNet parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Best polynomial degree: 1\n",
      "Best alpha: 0.001\n",
      "Best l1 ratio: 1\n",
      "\n",
      "------ Tuned Model ------\n",
      "New R^2: 0.59\n",
      "New MSE: 0.53\n"
     ]
    }
   ],
   "source": [
    "# Define search space for hyperparameters\n",
    "param_grid = {\n",
    "    'polynomialfeatures__degree': [1],\n",
    "    'elasticnet__alpha': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'elasticnet__l1_ratio': [0, 0.25, 0.5, 0.75, 1]\n",
    "}\n",
    "\n",
    "# Create model pipeline\n",
    "model = make_pipeline(\n",
    "    PolynomialFeatures(),\n",
    "    StandardScaler(),\n",
    "    ElasticNet()\n",
    ")\n",
    "\n",
    "# Grid search cross validation\n",
    "search = RandomizedSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "search.fit(X_train, y_train)\n",
    "best_model = search.best_estimator_\n",
    "\n",
    "# Find best parameters\n",
    "best_params = best_model.named_steps['elasticnet'].get_params()\n",
    "print('\\nBest polynomial degree:', search.best_estimator_.named_steps['polynomialfeatures'].degree)\n",
    "print('Best alpha:', best_params['alpha'])\n",
    "print('Best l1 ratio:', best_params['l1_ratio'])\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "print(\"\\n------ Tuned Model ------\")\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"New R^2: %.2f\" % r2_score(y_test, y_pred))\n",
    "print(\"New MSE: %.2f\" % mean_squared_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
